{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "#loading the data \n",
    "link = \"https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\"\n",
    "path = tf.keras.utils.get_file('mnist.npz',link)\n",
    "data = np.load(path)\n",
    "x_coord_train , y_coord_train = data[\"x_train\"], data[\"y_train\"]\n",
    "x_coord_test , y_coord_test = data[\"x_test\"], data[\"y_test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_classes = [0, 1] # making the array for the classes we want \n",
    "select_val_train = np.isin(y_coord_train, selected_classes) # using the np.isin function to get the selected classes\n",
    "select_val_test = np.isin(y_coord_test, selected_classes) # using the np.isin function to get the selected classes\n",
    "x_selected_train = x_coord_train[select_val_train] #selected x_train data -- the value of n is close to 18000\n",
    "y_selected_train = y_coord_train[select_val_train] #selected y_train data -- the value of n is close to 18000\n",
    "y_selected_train = np.where(y_selected_train == 0, -1, 1)  # changing the label 0 to -1 and 1 will remain 1\n",
    "x_selected_test = x_coord_test[select_val_test] #selected x_test data -- the value of n is close to 3000\n",
    "y_selected_test = y_coord_test[select_val_test] #selected y_test data -- the value of n is close to 3000\n",
    "y_selected_test = np.where(y_selected_test == 0, -1, 1) # changing the label 0 to -1 and 1 will remain 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the train set into train and val set. Keep 1000 samples from each\n",
    "class for val. Note val should be used to evaluate the performance of the\n",
    "classifier. Must not be used in obtaining PCA matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# dividing train set into train and val set . \n",
    "# indices_class_neg_1 = np.where(y_selected_train == -1)[0] # getting the indices of class -1\n",
    "# indices_class_1 = np.where(y_selected_train == 1)[0] # getting the indices of class 1\n",
    "# val_indices = np.concatenate((indices_class_neg_1[:1000] , indices_class_1[:1000])) # taking 1000 samples from each class \n",
    "# train_indices = np.concatenate((indices_class_neg_1[1000:] , indices_class_1[1000:])) # taking the rest of the samples for training\n",
    "val_points = [] ; val_y = [] ; train_points = [] ; y_train_points = []\n",
    "idx_class_neg1 = np.where(y_selected_train == -1)[0]\n",
    "idx_class_1 = np.where(y_selected_train == 1)[0]\n",
    "val_points.extend(x_selected_train[idx_class_neg1[:1000]])\n",
    "val_points.extend(x_selected_train[idx_class_1[:1000]])\n",
    "val_y.extend(y_selected_train[idx_class_neg1[:1000]])\n",
    "val_y.extend(y_selected_train[idx_class_1[:1000]])\n",
    "train_points.extend(x_selected_train[idx_class_neg1[1000:]])\n",
    "train_points.extend(x_selected_train[idx_class_1[1000:]])\n",
    "y_train_points.extend(y_selected_train[idx_class_neg1[1000:]])\n",
    "y_train_points.extend(y_selected_train[idx_class_1[1000:]])\n",
    "\n",
    "val_points = np.array(val_points) ; val_y = np.array(val_y) ; train_points = np.array(train_points) ; y_train_points = np.array(y_train_points)\n",
    "print(val_points.shape)\n",
    "# val_points = y_selected_train[val_indices] # getting the validation set\n",
    "# train_points = x_selected_train[train_indices] # getting the validation set\n",
    "# y_train_points = y_selected_train[train_indices] # getting the labels for the training set\n",
    "# print(val_points.shape)\n",
    "# print(train_points.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply PCA and reduce the dimension to p = 5. You can use the train set\n",
    "of the two classes to obtain PCA matrix. For the remaining parts, use the\n",
    "reduced dimension dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10665)\n",
      "(5, 2000)\n"
     ]
    }
   ],
   "source": [
    "# applying PCA matrix using the train_points \n",
    "p = 5\n",
    "train_points = train_points.reshape(train_points.shape[0], -1)\n",
    "# print(train_points.shape)\n",
    "train_points = train_points.T \n",
    "mean_train_points = np.mean(train_points , axis=1 , keepdims=True)\n",
    "train_centered = train_points - mean_train_points\n",
    "S = (train_centered @ train_centered.T) / (train_centered.shape[1]- 1)\n",
    "S_eigenvalues, S_eigenvectors = np.linalg.eig(S)\n",
    "sorted_S = np.argsort(S_eigenvalues)[::-1]\n",
    "S_eigenvalues = S_eigenvalues[sorted_S]\n",
    "S_eigenvectors = S_eigenvectors[:, sorted_S]\n",
    "U = S_eigenvectors\n",
    "U_p = U[:, :p]\n",
    "Y = U_p.T @ train_centered # applying the PCA matrix on the train_points to reduce the dimension of the data\n",
    "\n",
    "print(Y.shape)\n",
    "\n",
    "val_points = val_points.reshape(val_points.shape[0], -1)\n",
    "val_points = val_points.T\n",
    "mean_val_points = np.mean(val_points , axis=1 , keepdims=True)\n",
    "val_centered = val_points - mean_val_points\n",
    "S_val = (val_centered @ val_centered.T) / (val_centered.shape[1]- 1)\n",
    "S_eigenvalues_val, S_eigenvectors_val = np.linalg.eig(S_val)\n",
    "sorted_S_val = np.argsort(S_eigenvalues_val)[::-1]\n",
    "S_eigenvalues_val = S_eigenvalues_val[sorted_S_val]\n",
    "S_eigenvectors_val = S_eigenvectors_val[:, sorted_S_val]\n",
    "U_val = S_eigenvectors_val\n",
    "U_p_val = U_val[:, :p]\n",
    "X_val = U_p_val.T @ val_centered # applying the PCA matrix on the val_points to reduce the dimension of the data\n",
    "print(X_val.shape)\n",
    "\n",
    "test_points = x_selected_test.reshape(x_selected_test.shape[0], -1)\n",
    "test_points = test_points.T\n",
    "#mean_test_points = np.mean(test_points , axis=1 , keepdims=True)\n",
    "test_centered = test_points - mean_train_points\n",
    "S_test = (test_centered @ test_centered.T) / (test_centered.shape[1]- 1)\n",
    "S_eigenvalues_test, S_eigenvectors_test = np.linalg.eig(S_test)\n",
    "sorted_S_test = np.argsort(S_eigenvalues_test)[::-1]\n",
    "S_eigenvalues_test = S_eigenvalues_test[sorted_S_test]\n",
    "S_eigenvectors_test = S_eigenvectors_test[:, sorted_S_test]\n",
    "U_test = S_eigenvectors\n",
    "U_p_test = U_test[:, :p]\n",
    "X_test = U_p_test.T @ test_centered # applying the PCA matrix on the test_points to reduce the dimension of the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(weight, unique , train_points , y_train_points): \n",
    "    min_loss = 1.5  ; min_mid = 0 ; indexes_weight_changed = []  ; final_left_predict = 0 ; final_right_predict = 0 \n",
    "    mid_vals = ((unique[1:] + unique[:-1])/2)\n",
    "    for j in range(len(mid_vals)):\n",
    "        weights_changed_indices = []\n",
    "        # predicted_left = [] \n",
    "        # predicted_right = [] \n",
    "        mid = mid_vals[j] \n",
    "        # print(mid) \n",
    "        train_points = np.array(train_points) ; weight = np.array(weight)\n",
    "        # for k in range(len(train_points[dim])) : \n",
    "        #     if train_points[dim][k] < mid : \n",
    "        #         predicted_left.append(y_train_points[k])\n",
    "        #         predicted_left_indices.append(k)\n",
    "        #     else : \n",
    "        #         predicted_right.append(y_train_points[k])\n",
    "        #         predicted_right_indices.append(k)\n",
    "        # train_points = train_points.T     \n",
    "        # decision_split = train_points[:,dim] < mid\n",
    "        # # print(decision_split)\n",
    "        # decision_less = weight[decision_split]\n",
    "        # decision_more = weight[~decision_split]\n",
    "        # less_chosen = y_train_points[decision_split]\n",
    "        # more_chosen = y_train_points[~decision_split]\n",
    "        # indices_less = np.where(decision_split)[0]\n",
    "        # indices_more = np.where(~decision_split)[0]\n",
    "        # train_points = train_points.T\n",
    "        left_points = y_train_points[0:j] # taking first j points\n",
    "        right_points = y_train_points[j:len(y_train_points)]  # taking the rest of the points\n",
    "        weight_left = weight[0:j]   # taking the weights of the first j points\n",
    "        weight_right = weight[j:len(weight)] # taking the weights of the rest of the points\n",
    "        left_predict = 1 if np.sum(left_points) > 0 else -1 # making left prediction  \n",
    "        right_predict = 1 if np.sum(right_points) > 0 else -1 # making right prediction \n",
    "        # count_neg1_left = predicted_left.count(-1) ; count_1_left = predicted_left.count(1) ; count_neg1_right = predicted_right.count(-1) ; count_1_right = predicted_right.count(1)   \n",
    "        #print(count_neg1_left , count_1_left , count_neg1_right , count_1_right)\n",
    "        # if count_neg1_left > count_1_left:\n",
    "        #     left_predict = (-1) \n",
    "        # else: \n",
    "        #     left_predict = 1\n",
    "        # if count_neg1_right > count_1_right:\n",
    "        #     right_predict = (-1)\n",
    "        # else:\n",
    "        #     right_predict = 1    \n",
    "        # count_neg1_left = np.sum(less_chosen == -1) ; count_1_left = np.sum(less_chosen == 1) ; count_neg1_right = np.sum(more_chosen == -1) ; count_1_right = np.sum(more_chosen == 1)\n",
    "        # # print(count_neg1_left , count_1_left , count_neg1_right , count_1_right)\n",
    "        # left_predict = -1 if count_neg1_left > count_1_left else 1\n",
    "        # right_predict = -1 if count_neg1_right > count_1_right else 1   \n",
    "        # missclassified_weight = 0  ; misclassified_less = 0 ; misclassified_more = 0    \n",
    "        # misclassified_less = less_chosen != left_predict\n",
    "        # misclassified_more = more_chosen != right_predict\n",
    "        # missclassified_weight += np.sum(decision_less[misclassified_less])\n",
    "        # missclassified_weight += np.sum(decision_more[misclassified_more])\n",
    "        # weights_changed_indices.extend(indices_less[misclassified_less])\n",
    "        # weights_changed_indices.extend(indices_more[misclassified_more])\n",
    "        # for k in range(len(predicted_left)):\n",
    "        #     total_weight += weight[predicted_left_indices[k]]            \n",
    "        #     if predicted_left[k] != left_predict:\n",
    "        #         missclassified_weight += weight[predicted_left_indices[k]]\n",
    "        #         weights_changed_indices.append(predicted_left_indices[k])\n",
    "        #         # print(\"1\")\n",
    "        # for k in range(len(predicted_right)):\n",
    "        #     total_weight += weight[predicted_right_indices[k]]\n",
    "        #     if predicted_right[k] != right_predict:\n",
    "        #         missclassified_weight += weight[predicted_right_indices[k]]\n",
    "        #         weights_changed_indices.append(predicted_right_indices[k])         \n",
    "                # print(\"0\")\n",
    "        # print(total_weight)        \n",
    "        # print(missclassified_weight / total_weight )        \n",
    "        missclassified_weight = np.sum(weight_left[left_points != left_predict]) + np.sum(weight_right[right_points != right_predict]) ; total_weight = np.sum(weight)\n",
    "        if (missclassified_weight / total_weight) < min_loss:\n",
    "            min_loss = (missclassified_weight / total_weight)\n",
    "            min_mid = mid\n",
    "            indexes_weight_changed = weights_changed_indices\n",
    "            final_left_predict = left_predict\n",
    "            final_right_predict = right_predict\n",
    "            \n",
    "    return min_loss , min_mid , indexes_weight_changed , final_left_predict , final_right_predict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now learn a decision tree using the train set. You need to grow a deci-\n",
    "sion stump. For each dimension, find the unique values and sort them\n",
    "\n",
    "in ascending order. The splits to be evaluated will be midpoint of two\n",
    "consecutive unique values. Find the best split by minimizing weighted\n",
    "\n",
    "1\n",
    "\n",
    "miss-classification error. Denote this as h1(x). Note as we are dealing\n",
    "with real numbers, each value may be unique. So just sorting them and\n",
    "taking midpoint of consecutive values may also result in similar tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum loss is coming at dimension: 0 and loss is coming : 0.004688232536333803 and the split is happening at : (192.72278407732904+0j)\n",
      "Alpha is :  5.35800036870921\n",
      "The accuracy for 1 trees is : 99.5 %\n",
      "Minimum loss is coming at dimension: 0 and loss is coming : 0.24363727945600314 and the split is happening at : (637.0513407899206+0j)\n",
      "Alpha is :  1.132840490536242\n",
      "The accuracy for 2 trees is : 99.5 %\n",
      "Minimum loss is coming at dimension: 0 and loss is coming : 0.19133761691827686 and the split is happening at : (-294.5555128102518+0j)\n",
      "Alpha is :  1.4413420082504178\n",
      "The accuracy for 3 trees is : 99.5 %\n",
      "Minimum loss is coming at dimension: 3 and loss is coming : 0.2606771628395517 and the split is happening at : (143.1728062672899+0j)\n",
      "Alpha is :  1.04245196461968\n",
      "The accuracy for 4 trees is : 99.5 %\n",
      "Minimum loss is coming at dimension: 1 and loss is coming : 0.284860067708763 and the split is happening at : (-250.317415392733+0j)\n",
      "Alpha is :  0.9204801638458563\n",
      "The accuracy for 5 trees is : 99.5 %\n",
      "Minimum loss is coming at dimension: 2 and loss is coming : 0.2548989001401686 and the split is happening at : (-275.55634907102296+0j)\n",
      "Alpha is :  1.0726529171775303\n",
      "The accuracy for 6 trees is : 99.5 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 82\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# making 300 decision stump trees\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m---> 82\u001b[0m     min_dim , splitat , left_predict , right_predict , min_loss_val ,alpha1 , weights\u001b[38;5;241m=\u001b[39m \u001b[43mlearn_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     83\u001b[0m     \u001b[38;5;66;03m# print(weights)\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# print(weights[11])\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     stored_dimensions\u001b[38;5;241m.\u001b[39mappend(min_dim) ; stored_splits\u001b[38;5;241m.\u001b[39mappend(splitat) ; stored_left_predict\u001b[38;5;241m.\u001b[39mappend(left_predict) ; stored_right_predict\u001b[38;5;241m.\u001b[39mappend(right_predict) ; alphas\u001b[38;5;241m.\u001b[39mappend(alpha1)\n",
      "Cell \u001b[1;32mIn[7], line 20\u001b[0m, in \u001b[0;36mlearn_tree\u001b[1;34m(train_set, weights)\u001b[0m\n\u001b[0;32m     18\u001b[0m y_train_points_sorted \u001b[38;5;241m=\u001b[39m y_train_points[sorted_idx] ; weights_sorted \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(weights)[sorted_idx]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# print(train_set_sorted.shape , y_train_points_sorted.shape)\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m min_loss , min_mid  , indexes_c , left_predict , right_predict\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_sorted\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munique_points\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set_sorted\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_points_sorted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m midpoints\u001b[38;5;241m.\u001b[39mappend(min_mid)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# print(len(indexes_c))\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m, in \u001b[0;36mloss\u001b[1;34m(weight, unique, train_points, y_train_points)\u001b[0m\n\u001b[0;32m      8\u001b[0m mid \u001b[38;5;241m=\u001b[39m mid_vals[j] \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# print(mid) \u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m train_points \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_points\u001b[49m\u001b[43m)\u001b[49m ; weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(weight)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# for k in range(len(train_points[dim])) : \u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#     if train_points[dim][k] < mid : \u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#         predicted_left.append(y_train_points[k])\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# indices_more = np.where(~decision_split)[0]\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# train_points = train_points.T\u001b[39;00m\n\u001b[0;32m     28\u001b[0m left_points \u001b[38;5;241m=\u001b[39m y_train_points[\u001b[38;5;241m0\u001b[39m:j] \u001b[38;5;66;03m# taking first j points\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def learn_tree(train_set , weights):\n",
    "    # train_set[i][j] -- means that we are at ith dimension and at jth point\n",
    "    indexes_changed = [] ; midpoints=[] ; left_predictions = [] ; right_predictions = []\n",
    "    # print(weights)\n",
    "    min_losses = []\n",
    "    for i in range(5):\n",
    "        unique_points = np.unique(train_set[i]) \n",
    "        # for j in range(len(train_set[i])):\n",
    "        #     if train_set[i][j] not in unique_points:\n",
    "        #         unique_points.append(train_set[i][j])\n",
    "        # unique_points.sort()\n",
    "        # unique_points = np.random.choice(unique_points , 1000,replace=False)\n",
    "        # print(len(unique_points))\n",
    "        # print(unique_points)\n",
    "        # print(weights)\n",
    "        sorted_idx = np.argsort(train_set[i])\n",
    "        train_set_sorted = train_set.T[sorted_idx].T\n",
    "        y_train_points_sorted = y_train_points[sorted_idx] ; weights_sorted = np.array(weights)[sorted_idx]\n",
    "        # print(train_set_sorted.shape , y_train_points_sorted.shape)\n",
    "        min_loss , min_mid  , indexes_c , left_predict , right_predict= loss(weights_sorted , unique_points , train_set_sorted , y_train_points_sorted)\n",
    "        midpoints.append(min_mid)\n",
    "        # print(len(indexes_c))\n",
    "        indexes_changed.append(indexes_c)\n",
    "        \n",
    "        # print(min_loss , min_mid)\n",
    "        min_losses.append(min_loss)\n",
    "        left_predictions.append(left_predict)                                                        \n",
    "        right_predictions.append(right_predict)\n",
    "        # print(unique_points)     \n",
    "    min_dim = 0 ; min_loss_val = min_losses[0]  ; minloss_indexes = indexes_changed[0] ; splitat = midpoints[0] ; final_left_predict = left_predictions[0] ; final_right_predict = right_predictions[0]\n",
    "    for i in range(1,len(min_losses)):\n",
    "        if min_losses[i] < min_loss_val:\n",
    "            min_loss_val = min_losses[i]\n",
    "            min_dim = i\n",
    "            minloss_indexes = indexes_changed[i]\n",
    "            splitat = midpoints[i]\n",
    "            final_left_predict = left_predictions[i]    \n",
    "            final_right_predict = right_predictions[i]\n",
    "    print(\"Minimum loss is coming at dimension:\",min_dim , \"and loss is coming :\",min_loss_val , \"and the split is happening at :\",splitat)\n",
    "    \n",
    "# print(Y.shape)\n",
    "    alpha1 = np.log((1 - min_loss_val) / min_loss_val)\n",
    "    print(\"Alpha is : \",alpha1)\n",
    "    # print(minloss_indexes)\n",
    "    sorted_idx = np.argsort(train_set[min_dim])\n",
    "    \n",
    "    train_set_sorted = train_set.T[sorted_idx].T\n",
    "    # print(train_set_sorted.shape)\n",
    "    y_train_points_sorted = y_train_points[sorted_idx] \n",
    "    \n",
    "    sorted_weights = np.array(weights)[sorted_idx]\n",
    "    \n",
    "    y_sorted_left = y_train_points_sorted[train_set_sorted[min_dim] < splitat] \n",
    "    \n",
    "    y_sorted_right = y_train_points_sorted[train_set_sorted[min_dim] >= splitat]\n",
    "    \n",
    "    weights_less = sorted_weights[train_set_sorted[min_dim] < splitat]  \n",
    "    \n",
    "    weights_more = sorted_weights[train_set_sorted[min_dim] >= splitat]\n",
    "    \n",
    "    split_dec_left = 1 if np.sum(y_sorted_left) > 0 else -1 ; split_dec_right = 1 if np.sum(y_sorted_right) > 0 else -1\n",
    "    \n",
    "    weights_less[y_sorted_left != split_dec_left] = weights_less[y_sorted_left != split_dec_left] * ((1 - min_loss_val) / min_loss_val)\n",
    "    \n",
    "    weights_more[y_sorted_right != split_dec_right] = weights_more[y_sorted_right != split_dec_right] * ((1 - min_loss_val) / min_loss_val)\n",
    "    \n",
    "    sorted_weights = np.concatenate((weights_less , weights_more))\n",
    "    \n",
    "    first_idxeing = np.argsort(sorted_idx)\n",
    "    \n",
    "    weights = sorted_weights[first_idxeing]\n",
    "\n",
    "    \n",
    "        \n",
    "    # for i in range(len(minloss_indexes)):\n",
    "    #     weights[minloss_indexes[i]] = weights[minloss_indexes[i]] * ((1- min_loss_val) / min_loss_val)\n",
    "    # # print(weights[11])     \n",
    "    return min_dim , splitat , final_left_predict , final_right_predict , min_loss_val , alpha1 , weights\n",
    "weights = [1/(len(Y[0]))] * (len(Y[0])) ; stored_dimensions = [] ; stored_splits = [] ; stored_left_predict = [] ; stored_right_predict = [] ; accuracy = [] ; alphas =[]\n",
    "# making 300 decision stump trees\n",
    "for i in range(300):\n",
    "    min_dim , splitat , left_predict , right_predict , min_loss_val ,alpha1 , weights= learn_tree(Y , weights) \n",
    "    # print(weights)\n",
    "    # print(weights[11])\n",
    "    stored_dimensions.append(min_dim) ; stored_splits.append(splitat) ; stored_left_predict.append(left_predict) ; stored_right_predict.append(right_predict) ; alphas.append(alpha1)\n",
    "    # print(stored_dimensions , stored_splits , stored_left_predict , stored_right_predict , alphas)\n",
    "    true_classified = 0 \n",
    "    for j in range(len(X_val[0])):\n",
    "        f_x = 0 \n",
    "        for k in range(0,i+1):\n",
    "            f_x += (alphas[k] * (stored_left_predict[k] if X_val[stored_dimensions[k]][j] < stored_splits[k] else stored_right_predict[k]))\n",
    "        if np.sign(f_x) == val_y[j]:\n",
    "            true_classified += 1\n",
    "    print(f\"The accuracy for {i+1} trees is : {true_classified / len(X_val[0]) * 100} %\")          \n",
    "    accuracy.append(true_classified / len(X_val[0]))\n",
    "plt.plot(range(1, 301), accuracy, marker='o', linestyle='-')\n",
    "plt.title('Accuracy on val set vs. Number of Trees')\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.ylabel('Accuracy on val set')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "no_of_trees = 1 ; max_accuracy = accuracy[0]\n",
    "for i in range(1 ,len(accuracy) ,1):\n",
    "    if accuracy[i] >= max_accuracy:\n",
    "        no_of_trees = i+1\n",
    "        max_accuracy = accuracy[i]\n",
    "print(f\"The maximum accuracy is coming at {no_of_trees} trees and the accuracy is {max_accuracy * 100} %\")\n",
    "\n",
    "# seeing accuracy for test set \n",
    "true_classified = 0\n",
    "for j in range(len(X_test[0])):\n",
    "    f_x = 0\n",
    "    for k in range(no_of_trees):\n",
    "        f_x += (alphas[k] * (stored_left_predict[k] if X_test[stored_dimensions[k]][j] < stored_splits[k] else stored_right_predict[k]))\n",
    "    if np.sign(f_x) == y_selected_test[j]:\n",
    "        true_classified += 1\n",
    "print(f\"The accuracy for the test set is : {true_classified / len(X_test[0]) * 100} %\")    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 1 trees is : 0.980483181186607\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 2 trees is : 0.9611626416596478\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 3 trees is : 0.9420383814188985\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 4 trees is : 0.9231104004644752\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 5 trees is : 0.9043786987963917\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 6 trees is : 0.8858432764146039\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 7 trees is : 0.8675041333190918\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 8 trees is : 0.8493612695099724\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 9 trees is : 0.8314146849871772\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 10 trees is : 0.8136643797506103\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 11 trees is : 0.7961103538004057\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 12 trees is : 0.7787526071365715\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 13 trees is : 0.7615911397589763\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 14 trees is : 0.7446259516677269\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 15 trees is : 0.7278570428627872\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 16 trees is : 0.7112844133441211\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 17 trees is : 0.6949080631118323\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 18 trees is : 0.6787279921658415\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 19 trees is : 0.6627442005061428\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 20 trees is : 0.646956688132774\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 21 trees is : 0.6313654550457392\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 22 trees is : 0.615970501245024\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 23 trees is : 0.6007718267306064\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 24 trees is : 0.5857694315025124\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 25 trees is : 0.5709633155606938\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 26 trees is : 0.5563534789052376\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 27 trees is : 0.5419399215360755\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 28 trees is : 0.5277226434532384\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 29 trees is : 0.5137016446567177\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 30 trees is : 0.4998769251465372\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 31 trees is : 0.48624848492261985\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 32 trees is : 0.47281632398503726\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 33 trees is : 0.45958044233377593\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 34 trees is : 0.4465408399688315\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 35 trees is : 0.4336975168902234\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 36 trees is : 0.4210504730978987\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 37 trees is : 0.4085997085918909\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 38 trees is : 0.3963452233722061\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 39 trees is : 0.38428701743885013\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 40 trees is : 0.372425090791785\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 41 trees is : 0.360759443431065\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 42 trees is : 0.34929007535664874\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 43 trees is : 0.33801698656853635\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 44 trees is : 0.32694017706673306\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 45 trees is : 0.3160596468512752\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 46 trees is : 0.30537539592210217\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 47 trees is : 0.29488742427925396\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 48 trees is : 0.28459573192273746\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 49 trees is : 0.2745003188525198\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 50 trees is : 0.2646011850686275\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 51 trees is : 0.25489833057103306\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 52 trees is : 0.24539175535976623\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 53 trees is : 0.2360814594348318\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 54 trees is : 0.22696744279619233\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 55 trees is : 0.21804970544387858\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 56 trees is : 0.2093282473778672\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 57 trees is : 0.2008030685981819\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 58 trees is : 0.19247416910480059\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 59 trees is : 0.18434154889776028\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 60 trees is : 0.17640520797700748\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 61 trees is : 0.16866514634258417\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 62 trees is : 0.1611213639944737\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 63 trees is : 0.15377386093267728\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 64 trees is : 0.1466226371572027\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 65 trees is : 0.13966769266804108\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 66 trees is : 0.13290902746519168\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 67 trees is : 0.12634664154865377\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 68 trees is : 0.11998053491844586\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 69 trees is : 0.11381070757453512\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 70 trees is : 0.1078371595169515\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 71 trees is : 0.10205989074568166\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 72 trees is : 0.09647890126072696\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 73 trees is : 0.09109419106209277\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 74 trees is : 0.08590576014976525\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 75 trees is : 0.08091360852375926\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 76 trees is : 0.07611773618406491\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 77 trees is : 0.07151814313068418\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 78 trees is : 0.06711482936362792\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 79 trees is : 0.06290779488287913\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 80 trees is : 0.058897039688450926\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 81 trees is : 0.055082563780335506\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 82 trees is : 0.05146436715853324\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 83 trees is : 0.048042449823051885\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 84 trees is : 0.0448168117738834\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 85 trees is : 0.04178745301102803\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 86 trees is : 0.03895437353449094\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 87 trees is : 0.036317573344269605\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 88 trees is : 0.0338770524403641\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 89 trees is : 0.031632810822773\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 90 trees is : 0.029584848491498315\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 91 trees is : 0.027733165446537502\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 92 trees is : 0.02607776168789372\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 93 trees is : 0.024618637215565446\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 94 trees is : 0.023355792029552326\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 95 trees is : 0.0222892261298551\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 96 trees is : 0.021418939516472453\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 97 trees is : 0.020744932189406925\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 98 trees is : 0.020267204148655404\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 99 trees is : 0.01998575539422013\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 100 trees is : 0.019900585926100105\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 101 trees is : 0.020011695744295507\n",
      "The minimum loss is coming as: 0.0 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 102 trees is : 0.019900475500779613\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 103 trees is : 0.02000973371179116\n",
      "The minimum loss is coming as: 0.0 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 104 trees is : 0.01990038257477428\n",
      "The minimum loss is coming as: 199.06068291042573 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 105 trees is : 0.020007789178601302\n",
      "The minimum loss is coming as: 110.98316616766233 at dimension: 3 and the split is happening at: (168.89744536772724+0j)\n",
      "The MSE for 106 trees is : 0.020097796854538635\n",
      "The minimum loss is coming as: 87.59645026706691 at dimension: 3 and the split is happening at: (84.9624451819993+0j)\n",
      "The MSE for 107 trees is : 0.020007415451424565\n",
      "The minimum loss is coming as: 2450.090827123433 at dimension: 3 and the split is happening at: (85.00169485495394+0j)\n",
      "The MSE for 108 trees is : 0.020059354690665752\n",
      "The minimum loss is coming as: 87.59645026706691 at dimension: 3 and the split is happening at: (84.9624451819993+0j)\n",
      "The MSE for 109 trees is : 0.019996880440471307\n",
      "The minimum loss is coming as: 110.98316616766233 at dimension: 3 and the split is happening at: (168.89744536772724+0j)\n",
      "The MSE for 110 trees is : 0.02005884276040257\n",
      "The minimum loss is coming as: 87.59645026706691 at dimension: 3 and the split is happening at: (84.9624451819993+0j)\n",
      "The MSE for 111 trees is : 0.01999666709426194\n",
      "The minimum loss is coming as: 110.98316616766233 at dimension: 3 and the split is happening at: (168.89744536772724+0j)\n",
      "The MSE for 112 trees is : 0.02005833674719275\n",
      "The minimum loss is coming as: 87.59645026706691 at dimension: 3 and the split is happening at: (84.9624451819993+0j)\n",
      "The MSE for 113 trees is : 0.019996459665106416\n",
      "The minimum loss is coming as: 110.98316616766233 at dimension: 3 and the split is happening at: (168.89744536772724+0j)\n",
      "The MSE for 114 trees is : 0.020057836651036595\n",
      "The minimum loss is coming as: 87.59645026706691 at dimension: 3 and the split is happening at: (84.9624451819993+0j)\n",
      "The MSE for 115 trees is : 0.019996258153003665\n",
      "The minimum loss is coming as: 110.98316616766233 at dimension: 3 and the split is happening at: (168.89744536772724+0j)\n",
      "The MSE for 116 trees is : 0.020057342471933273\n",
      "The minimum loss is coming as: 87.59645026706691 at dimension: 3 and the split is happening at: (84.9624451819993+0j)\n",
      "The MSE for 117 trees is : 0.01999606255795477\n",
      "The minimum loss is coming as: 110.98316616766233 at dimension: 3 and the split is happening at: (168.89744536772724+0j)\n",
      "The MSE for 118 trees is : 0.020056854209883908\n",
      "The minimum loss is coming as: 87.59645026706691 at dimension: 3 and the split is happening at: (84.9624451819993+0j)\n",
      "The MSE for 119 trees is : 0.01999587287995793\n",
      "The minimum loss is coming as: 110.98316616766233 at dimension: 3 and the split is happening at: (168.89744536772724+0j)\n",
      "The MSE for 120 trees is : 0.020056371864886\n",
      "The minimum loss is coming as: 87.59645026706691 at dimension: 3 and the split is happening at: (84.9624451819993+0j)\n",
      "The MSE for 121 trees is : 0.01999568911901466\n",
      "The minimum loss is coming as: 110.98316616766233 at dimension: 3 and the split is happening at: (168.89744536772724+0j)\n",
      "The MSE for 122 trees is : 0.020055895436943205\n",
      "The minimum loss is coming as: 87.59645026706691 at dimension: 3 and the split is happening at: (84.9624451819993+0j)\n",
      "The MSE for 123 trees is : 0.01999551127512547\n",
      "The minimum loss is coming as: 110.98316616766233 at dimension: 3 and the split is happening at: (168.89744536772724+0j)\n",
      "The MSE for 124 trees is : 0.020055424926052633\n",
      "The minimum loss is coming as: 87.59645026706691 at dimension: 3 and the split is happening at: (84.9624451819993+0j)\n",
      "The MSE for 125 trees is : 0.01999533934828778\n",
      "The minimum loss is coming as: 110.98316616766233 at dimension: 3 and the split is happening at: (168.89744536772724+0j)\n",
      "The MSE for 126 trees is : 0.020054960332215137\n",
      "The minimum loss is coming as: 87.59645026706691 at dimension: 3 and the split is happening at: (84.9624451819993+0j)\n",
      "The MSE for 127 trees is : 0.01999517333850532\n",
      "The minimum loss is coming as: 110.98316616766233 at dimension: 3 and the split is happening at: (168.89744536772724+0j)\n",
      "The MSE for 128 trees is : 0.020054501655430948\n",
      "The minimum loss is coming as: 87.59645026706691 at dimension: 3 and the split is happening at: (84.9624451819993+0j)\n",
      "The MSE for 129 trees is : 0.019995013245774424\n",
      "The minimum loss is coming as: 110.98316616766233 at dimension: 3 and the split is happening at: (168.89744536772724+0j)\n",
      "The MSE for 130 trees is : 0.02005404889570028\n",
      "The minimum loss is coming as: 87.59645026706691 at dimension: 3 and the split is happening at: (84.9624451819993+0j)\n",
      "The MSE for 131 trees is : 0.01999485907009726\n",
      "The minimum loss is coming as: 110.98316616766233 at dimension: 3 and the split is happening at: (168.89744536772724+0j)\n",
      "The MSE for 132 trees is : 0.020053602053021036\n",
      "The minimum loss is coming as: 87.59645026706691 at dimension: 3 and the split is happening at: (84.9624451819993+0j)\n",
      "The MSE for 133 trees is : 0.019994710811473127\n",
      "The minimum loss is coming as: 110.98316616766233 at dimension: 3 and the split is happening at: (168.89744536772724+0j)\n",
      "The MSE for 134 trees is : 0.020053161127397905\n",
      "The minimum loss is coming as: 87.59645026706691 at dimension: 3 and the split is happening at: (84.9624451819993+0j)\n",
      "The MSE for 135 trees is : 0.019994568469902732\n",
      "The minimum loss is coming as: 110.98316616766233 at dimension: 3 and the split is happening at: (168.89744536772724+0j)\n",
      "The MSE for 136 trees is : 0.020052726118825442\n",
      "The minimum loss is coming as: 87.59645026706691 at dimension: 3 and the split is happening at: (84.9624451819993+0j)\n",
      "The MSE for 137 trees is : 0.019994432045384182\n",
      "The minimum loss is coming as: 110.98316616766233 at dimension: 3 and the split is happening at: (168.89744536772724+0j)\n",
      "The MSE for 138 trees is : 0.02005229702730756\n",
      "The minimum loss is coming as: 87.59645026706691 at dimension: 3 and the split is happening at: (84.9624451819993+0j)\n",
      "The MSE for 139 trees is : 0.0199943015379206\n",
      "The minimum loss is coming as: 110.98316616766233 at dimension: 3 and the split is happening at: (168.89744536772724+0j)\n",
      "The MSE for 140 trees is : 0.02005187385284339\n",
      "The minimum loss is coming as: 87.59645026706691 at dimension: 3 and the split is happening at: (84.9624451819993+0j)\n",
      "The MSE for 141 trees is : 0.019994176947509757\n",
      "The minimum loss is coming as: 110.98316616766233 at dimension: 3 and the split is happening at: (168.89744536772724+0j)\n",
      "The MSE for 142 trees is : 0.020051456595430426\n",
      "The minimum loss is coming as: 87.59645026706691 at dimension: 3 and the split is happening at: (84.9624451819993+0j)\n",
      "The MSE for 143 trees is : 0.019994058274151745\n",
      "The minimum loss is coming as: 110.98316616766233 at dimension: 3 and the split is happening at: (168.89744536772724+0j)\n",
      "The MSE for 144 trees is : 0.020051045255073195\n",
      "The minimum loss is coming as: 87.59645026706691 at dimension: 3 and the split is happening at: (84.9624451819993+0j)\n",
      "The MSE for 145 trees is : 0.019993945517846414\n",
      "The minimum loss is coming as: 110.98316616766233 at dimension: 3 and the split is happening at: (168.89744536772724+0j)\n",
      "The MSE for 146 trees is : 0.020050639831767574\n",
      "The minimum loss is coming as: 87.59645026706691 at dimension: 3 and the split is happening at: (84.9624451819993+0j)\n",
      "The MSE for 147 trees is : 0.019993838678595142\n",
      "The minimum loss is coming as: 110.98316616766233 at dimension: 3 and the split is happening at: (168.89744536772724+0j)\n",
      "The MSE for 148 trees is : 0.02005024032551506\n",
      "The minimum loss is coming as: 87.59645026706691 at dimension: 3 and the split is happening at: (84.9624451819993+0j)\n",
      "The MSE for 149 trees is : 0.019993737756396842\n",
      "The minimum loss is coming as: 110.98316616766233 at dimension: 3 and the split is happening at: (168.89744536772724+0j)\n",
      "The MSE for 150 trees is : 0.02004984673631475\n",
      "The minimum loss is coming as: 87.59645026706691 at dimension: 3 and the split is happening at: (84.9624451819993+0j)\n",
      "The MSE for 151 trees is : 0.019993642751251022\n",
      "The minimum loss is coming as: 110.98316616766233 at dimension: 3 and the split is happening at: (168.89744536772724+0j)\n",
      "The MSE for 152 trees is : 0.020049459064169925\n",
      "The minimum loss is coming as: 87.59645026706691 at dimension: 3 and the split is happening at: (84.9624451819993+0j)\n",
      "The MSE for 153 trees is : 0.019993553663158112\n",
      "The minimum loss is coming as: 110.98316616766233 at dimension: 3 and the split is happening at: (168.89744536772724+0j)\n",
      "The MSE for 154 trees is : 0.020049077309076277\n",
      "The minimum loss is coming as: 87.59645026706691 at dimension: 3 and the split is happening at: (84.9624451819993+0j)\n",
      "The MSE for 155 trees is : 0.019993470492119154\n",
      "The minimum loss is coming as: 110.98316616766233 at dimension: 3 and the split is happening at: (168.89744536772724+0j)\n",
      "The MSE for 156 trees is : 0.020048701471036597\n",
      "The minimum loss is coming as: 87.59645026706691 at dimension: 3 and the split is happening at: (84.9624451819993+0j)\n",
      "The MSE for 157 trees is : 0.019993393238133948\n",
      "The minimum loss is coming as: 2996.689648187127 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 158 trees is : 0.01999523638007918\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 159 trees is : 0.02000426795556471\n",
      "The minimum loss is coming as: 614.8449100817153 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 160 trees is : 0.01999263112479574\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 161 trees is : 0.020006612676681704\n",
      "The minimum loss is coming as: 614.8449100817153 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 162 trees is : 0.019990256439130962\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 163 trees is : 0.02000918796741844\n",
      "The minimum loss is coming as: 614.8449100817153 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 164 trees is : 0.019988112323086598\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 165 trees is : 0.020011993827775233\n",
      "The minimum loss is coming as: 614.8449100817153 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 166 trees is : 0.01998619877666121\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 167 trees is : 0.020015030257751854\n",
      "The minimum loss is coming as: 614.8449100817153 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 168 trees is : 0.019984515799856453\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 169 trees is : 0.02001829725734814\n",
      "The minimum loss is coming as: 614.8449100817153 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 170 trees is : 0.019983063392670666\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 171 trees is : 0.02002179482656349\n",
      "The minimum loss is coming as: 614.8449100817153 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 172 trees is : 0.019981841555105476\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 173 trees is : 0.020025522965398636\n",
      "The minimum loss is coming as: 614.8449100817153 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 174 trees is : 0.019980850287158042\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 175 trees is : 0.020029481673853648\n",
      "The minimum loss is coming as: 614.8449100817153 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 176 trees is : 0.019980089588833124\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 177 trees is : 0.02003367095192855\n",
      "The minimum loss is coming as: 614.8449100817153 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 178 trees is : 0.019979559460125352\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 179 trees is : 0.020038090799622717\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 180 trees is : 0.01997948385493696\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 181 trees is : 0.020038243697747874\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 182 trees is : 0.01997940876458884\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 183 trees is : 0.02003839711071342\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 184 trees is : 0.01997933418908122\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 185 trees is : 0.020038551038519127\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 186 trees is : 0.019979260128413785\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 187 trees is : 0.02003870548116533\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 188 trees is : 0.01997918658258677\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 189 trees is : 0.020038860438651832\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 190 trees is : 0.019979113551600255\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 191 trees is : 0.02003901591097867\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 192 trees is : 0.019979041035453924\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 193 trees is : 0.02003917189814575\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 194 trees is : 0.019978969034148256\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 195 trees is : 0.02003932840015322\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 196 trees is : 0.019978897547682575\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 197 trees is : 0.02003948541700124\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 198 trees is : 0.019978826576057415\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 199 trees is : 0.020039642948689554\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 200 trees is : 0.01997875611927251\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 201 trees is : 0.02003980099521813\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 202 trees is : 0.01997868617732826\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 203 trees is : 0.020039959556587276\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 204 trees is : 0.019978616750223888\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 205 trees is : 0.020040118632796537\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 206 trees is : 0.01997854783796034\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 207 trees is : 0.020040278223846256\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 208 trees is : 0.019978479440536944\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 209 trees is : 0.020040438329736263\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 210 trees is : 0.01997841155795405\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 211 trees is : 0.020040598950466882\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 212 trees is : 0.01997834419021133\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 213 trees is : 0.020040760086037623\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 214 trees is : 0.01997827733730905\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 215 trees is : 0.02004092173644881\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 216 trees is : 0.019978210999247015\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 217 trees is : 0.020041083901700323\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 218 trees is : 0.019978145176025676\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 219 trees is : 0.020041246581792252\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 220 trees is : 0.01997807986764418\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 221 trees is : 0.02004140977672442\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 222 trees is : 0.01997801507410344\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 223 trees is : 0.0200415734864972\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 224 trees is : 0.019977950795402974\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 225 trees is : 0.02004173771111002\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 226 trees is : 0.019977887031542782\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 227 trees is : 0.020041902450563358\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 228 trees is : 0.01997782378252299\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 229 trees is : 0.020042067704857187\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 230 trees is : 0.019977761048343673\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 231 trees is : 0.020042233473991377\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 232 trees is : 0.019977698829004586\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 233 trees is : 0.02004239975796557\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 234 trees is : 0.01997763712450582\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 235 trees is : 0.020042566556780394\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 236 trees is : 0.019977575934847808\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 237 trees is : 0.02004273387043552\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 238 trees is : 0.019977515260029638\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 239 trees is : 0.02004290169893102\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 240 trees is : 0.01997745510005214\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 241 trees is : 0.0200430700422669\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 242 trees is : 0.01997739545491485\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 243 trees is : 0.02004323890044318\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 244 trees is : 0.01997733632461808\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 245 trees is : 0.020043408273459705\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 246 trees is : 0.019977277709161415\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 247 trees is : 0.020043578161316685\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 248 trees is : 0.019977219608545243\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 249 trees is : 0.020043748564013957\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 250 trees is : 0.01997716202276937\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 251 trees is : 0.020043919481551695\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 252 trees is : 0.019977104951834142\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 253 trees is : 0.0200440909139297\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 254 trees is : 0.019977048395738838\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 255 trees is : 0.02004426286114805\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 256 trees is : 0.01997699235448426\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 257 trees is : 0.020044435323206735\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 258 trees is : 0.0199769368280699\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 259 trees is : 0.020044608300105918\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 260 trees is : 0.01997688181649609\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 261 trees is : 0.020044781791845313\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 262 trees is : 0.019976827319762094\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 263 trees is : 0.020044955798425246\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 264 trees is : 0.01997677333786896\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 265 trees is : 0.020045130319845558\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 266 trees is : 0.019976719870816194\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 267 trees is : 0.020045305356106054\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 268 trees is : 0.01997666691860344\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 269 trees is : 0.02004548090720684\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 270 trees is : 0.019976614481231357\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 271 trees is : 0.020045656973148186\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 272 trees is : 0.019976562558699514\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 273 trees is : 0.020045833553929887\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 274 trees is : 0.019976511151008035\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 275 trees is : 0.02004601064955175\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 276 trees is : 0.01997646025815696\n",
      "The minimum loss is coming as: 87.63947858472999 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 277 trees is : 0.02004618826001412\n",
      "The minimum loss is coming as: 111.41601489757913 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 278 trees is : 0.019976409880146175\n",
      "The minimum loss is coming as: 4718.735701035353 at dimension: 3 and the split is happening at: (-214.80149682952168+0j)\n",
      "The MSE for 279 trees is : 0.019998231996235974\n",
      "The minimum loss is coming as: 593.5143711197977 at dimension: 3 and the split is happening at: (-214.80149682952168+0j)\n",
      "The MSE for 280 trees is : 0.019986693941282337\n",
      "The minimum loss is coming as: 4471.565776914864 at dimension: 3 and the split is happening at: (-214.80149682952168+0j)\n",
      "The MSE for 281 trees is : 0.019977745089154442\n",
      "The minimum loss is coming as: 2638.2621292251088 at dimension: 3 and the split is happening at: (-214.80149682952168+0j)\n",
      "The MSE for 282 trees is : 0.01999613559100195\n",
      "The minimum loss is coming as: 4471.565776914864 at dimension: 3 and the split is happening at: (-214.80149682952168+0j)\n",
      "The MSE for 283 trees is : 0.01997152000902823\n",
      "The minimum loss is coming as: 2638.2621292251088 at dimension: 3 and the split is happening at: (-214.80149682952168+0j)\n",
      "The MSE for 284 trees is : 0.020008328815186053\n",
      "The minimum loss is coming as: 3868.509902001091 at dimension: 3 and the split is happening at: (-214.80149682952168+0j)\n",
      "The MSE for 285 trees is : 0.019968927144406786\n",
      "The minimum loss is coming as: 4770.395259676911 at dimension: 3 and the split is happening at: (188.6210531335908+0j)\n",
      "The MSE for 286 trees is : 0.01992347937410309\n",
      "The minimum loss is coming as: 426.6260252265985 at dimension: 3 and the split is happening at: (171.31708291723254+0j)\n",
      "The MSE for 287 trees is : 0.019956277680135658\n",
      "The minimum loss is coming as: 4594.491028909317 at dimension: 3 and the split is happening at: (171.31708291723254+0j)\n",
      "The MSE for 288 trees is : 0.019909021148720132\n",
      "The minimum loss is coming as: 426.6260252265985 at dimension: 3 and the split is happening at: (171.31708291723254+0j)\n",
      "The MSE for 289 trees is : 0.019986875519550116\n",
      "The minimum loss is coming as: 4594.491028909317 at dimension: 3 and the split is happening at: (171.31708291723254+0j)\n",
      "The MSE for 290 trees is : 0.01990771163607397\n",
      "The minimum loss is coming as: 5745.385863369513 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 291 trees is : 0.0198083508661034\n",
      "The minimum loss is coming as: 4624.018938163796 at dimension: 3 and the split is happening at: (-217.45184391926358+0j)\n",
      "The MSE for 292 trees is : 0.01982220728098093\n",
      "The minimum loss is coming as: 2833.9641708773543 at dimension: 3 and the split is happening at: (-217.1601575158683+0j)\n",
      "The MSE for 293 trees is : 0.0198149211726713\n",
      "The minimum loss is coming as: 4624.018938163796 at dimension: 3 and the split is happening at: (-217.45184391926358+0j)\n",
      "The MSE for 294 trees is : 0.019813509488986223\n",
      "The minimum loss is coming as: 4950.429148123879 at dimension: 3 and the split is happening at: (219.58273800312907+0j)\n",
      "The MSE for 295 trees is : 0.019796651517792755\n",
      "The minimum loss is coming as: 500.75463966134953 at dimension: 3 and the split is happening at: (205.45816828159732+0j)\n",
      "The MSE for 296 trees is : 0.01983017917042667\n",
      "The minimum loss is coming as: 4891.550636917861 at dimension: 3 and the split is happening at: (193.94715833993246+0j)\n",
      "The MSE for 297 trees is : 0.01978025807330341\n",
      "The minimum loss is coming as: 3766.5325947258934 at dimension: 0 and the split is happening at: (189.85586681021414+0j)\n",
      "The MSE for 298 trees is : 0.019687646422718676\n",
      "The minimum loss is coming as: 492.54371943595993 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 299 trees is : 0.019662254273380284\n",
      "The minimum loss is coming as: 3681.787593439579 at dimension: 0 and the split is happening at: (663.1852052750012+0j)\n",
      "The MSE for 300 trees is : 0.01966746410075799\n"
     ]
    }
   ],
   "source": [
    "#Question - 2 - normal\n",
    "def loss_regressor(unique , train_points , y_train_points): \n",
    "    mid_vals = ((unique[1:] + unique[:-1])/2) ; SSR_arr = []; left_means = [] ;right_means = [] \n",
    "    for j in range(1,len(mid_vals)):\n",
    "        mid = mid_vals[j] \n",
    "        train_points = np.array(train_points) ; \n",
    "        left_points = y_train_points[0:j] # taking first j points\n",
    "        right_points = y_train_points[j:len(y_train_points)]  # taking the rest of the points\n",
    "        # print(left_points , right_points)\n",
    "        left_mean = np.mean(left_points) ; right_mean = np.mean(right_points)\n",
    "        left_points = left_points - left_mean ; left_points = left_points**2  ; right_points = right_points - right_mean ; right_points = right_points**2\n",
    "        sum_left = np.sum(left_points) ; sum_right = np.sum(right_points)\n",
    "        SSR = sum_left + sum_right\n",
    "        SSR_arr.append(SSR) ; \n",
    "        left_means.append(left_mean) ; right_means.append(right_mean)\n",
    "    min_loss = np.min(SSR_arr) ; min_mid = mid_vals[np.argmin(SSR_arr)] ; min_left_mean = left_means[np.argmin(SSR_arr)] ; min_right_mean = right_means[np.argmin(SSR_arr)]\n",
    "    # print(min_loss)\n",
    "    return min_loss , min_mid , min_left_mean , min_right_mean \n",
    "        \n",
    "def learn_tree_regressor(train_set , y_train_points , residue):\n",
    "    losses = [] ; midpoints = [] ; left_means = [] ; right_means = []\n",
    "    for i in range(5):\n",
    "        unique_points = np.unique(train_set[i]) \n",
    "        sorted_idx = np.argsort(train_set[i])\n",
    "        train_set_sorted = train_set.T[sorted_idx].T\n",
    "        y_train_points_sorted = y_train_points[sorted_idx]\n",
    "        min_loss_i , min_mid_i , min_left_mean_i , min_right_mean_i = loss_regressor(unique_points , train_set_sorted , y_train_points_sorted)\n",
    "        losses.append(min_loss_i) ; midpoints.append(min_mid_i) ; left_means.append(min_left_mean_i) ; right_means.append(min_right_mean_i)\n",
    "    min_dim = 0 ; min_loss_val = losses[0] ; splitat = midpoints[0] ; final_left_mean = left_means[0] ; final_right_mean = right_means[0]\n",
    "    for i in range(1,len(losses)):\n",
    "        if losses[i] < min_loss_val:\n",
    "            min_loss_val = losses[i]\n",
    "            min_dim = i\n",
    "            splitat = midpoints[i]\n",
    "            final_left_mean = left_means[i]    \n",
    "            final_right_mean = right_means[i]\n",
    "    sorted_idx = np.argsort(train_set[min_dim])\n",
    "    train_set_sorted = train_set.T[sorted_idx].T\n",
    "    # print(train_set_sorted.shape )\n",
    "    y_train_points_sorted = y_train_points[sorted_idx]\n",
    "    residue_sorted = residue[sorted_idx]\n",
    "    residue_less = residue_sorted[train_set_sorted[min_dim] < splitat] - 0.01*final_left_mean\n",
    "    residue_more = residue_sorted[train_set_sorted[min_dim] >= splitat] - 0.01*final_right_mean\n",
    "    sorted_y_train_less = y_train_points_sorted[train_set_sorted[min_dim] < splitat]\n",
    "    sorted_y_train_more = y_train_points_sorted[train_set_sorted[min_dim] >= splitat]\n",
    "    sorted_y_train_less = np.where(residue_less >= 0 , 1 , -1)\n",
    "    sorted_y_train_more = np.where(residue_more >= 0 , 1 , -1)\n",
    "    sorted_y_train_points = np.concatenate((sorted_y_train_less , sorted_y_train_more))\n",
    "    first_idxeing = np.argsort(sorted_idx)\n",
    "    y_train_points = sorted_y_train_points[first_idxeing]\n",
    "    residue_new = np.concatenate((residue_less , residue_more))\n",
    "    residue = residue_new[first_idxeing]           \n",
    "    print(f\"The minimum loss is coming as: {min_loss_val} at dimension: {min_dim} and the split is happening at: {splitat}\")\n",
    "    return min_dim , splitat , final_left_mean , final_right_mean , min_loss_val , y_train_points , residue \n",
    "dimensions = [] ; splits = [] ; left_means = [] ; right_means = []  ; MSE_arr = [] ; residue = y_train_points\n",
    "# avg_y = np.mean(y_train_points)\n",
    "# y_train_points = np.where(residue < 0 , -1 , 1)\n",
    "for i in range(300):\n",
    "    min_dim , splitat , left_mean , right_mean , min_loss_val , y_train_points , residue= learn_tree_regressor(Y , y_train_points ,residue)\n",
    "    dimensions.append(min_dim) ; splits.append(splitat) ; left_means.append(left_mean) ; right_means.append(right_mean)\n",
    "    MSE = 0 \n",
    "    for j in range(len(X_val[0])):\n",
    "        f_x = 0\n",
    "        for k in range(i+1):\n",
    "            f_x += 0.01*( left_means[k]   if X_val[dimensions[k]][j] < splits[k] else right_means[k]) \n",
    "        MSE += (f_x - val_y[j])**2    \n",
    "    MSE = MSE / len(X_val[0])\n",
    "    MSE_arr.append(MSE) \n",
    "    print(f\"The MSE for {i+1} trees is : {MSE}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, 301), MSE_arr)\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.ylabel('Mean Squared Error (MSE) on val set')\n",
    "plt.title('MSE on val set vs. Number of Trees')\n",
    "plt.grid(True)\n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum MSE is coming at 299 trees and the minimum MSE is 0.019662254273380284\n",
      "The MSE for the test set is : 0.015011203546894862\n"
     ]
    }
   ],
   "source": [
    "no_of_trees = 1 ; min_MSE = MSE_arr[0]\n",
    "for i in range(1 ,len(MSE_arr) ,1):\n",
    "    if MSE_arr[i] <= min_MSE:\n",
    "        no_of_trees = i+1\n",
    "        min_MSE = MSE_arr[i]\n",
    "print(f\"The minimum MSE is coming at {no_of_trees} trees and the minimum MSE is {min_MSE}\")\n",
    "\n",
    "MSE_test = 0 \n",
    "for j in range(len(X_test[0])):\n",
    "    f_x = 0\n",
    "    for k in range(no_of_trees):\n",
    "        f_x += 0.01*( left_means[k]   if X_test[dimensions[k]][j] < splits[k] else right_means[k])    \n",
    "    MSE_test += (f_x - y_selected_test[j])**2\n",
    "print(f\"The MSE for the test set is : {MSE_test / len(X_test[0])}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
