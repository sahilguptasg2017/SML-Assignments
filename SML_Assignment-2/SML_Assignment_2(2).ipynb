{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ecu151SONXB1",
        "outputId": "9a898f15-bc9b-4c4f-9b0d-27989a37cddc"
      },
      "outputs": [],
      "source": [
        "# Question - 1\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "link = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz'\n",
        "path = tf.keras.utils.get_file('mnist.npz' , link)\n",
        "data = np.load(path)\n",
        "x_coord_train , y_coord_train = data[\"x_train\"], data[\"y_train\"]\n",
        "x_coord_test , y_coord_test = data[\"x_test\"], data[\"y_test\"]\n",
        "#print(x_coord_train.shape)\n",
        "#print(y_coord_train.shape)\n",
        "x_coord_train_vectorized = x_coord_train.reshape(x_coord_train.shape[0],-1)\n",
        "x_coord_test_vectorized = x_coord_test.reshape(x_coord_test.shape[0],-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "samples = {val:[] for val in range(10)}\n",
        "\n",
        "for i in range(len(y_coord_train)):\n",
        "    val = y_coord_train[i]\n",
        "    if len(samples[val]) < 5:\n",
        "        samples[val].append(x_coord_train[i])\n",
        "\n",
        "\n",
        "plt.figure(figsize=(5,10))\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    for j in range(5):\n",
        "        plt.subplot(10, 5, i*5 + j + 1)\n",
        "        plt.imshow(samples[i][j], cmap='gray')\n",
        "        plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# vectorizing the images\n",
        "#print(x_coord_train.shape)\n",
        "#print(x_coord_test.shape)\n",
        "#print(x_coord_train_vectorized.shape)\n",
        "#print(x_coord_test_vectorized.shape)\n",
        "#computing the mean and covariance of the classes\n",
        "mean_of_classes = []\n",
        "covariance_of_classes = []\n",
        "for i in range(10):\n",
        "    curr_class = []\n",
        "    for j in range(len(x_coord_train_vectorized)):\n",
        "        if y_coord_train[j] == i:\n",
        "            curr_class.append(x_coord_train_vectorized[j])\n",
        "    curr_mean = np.mean(curr_class , axis= 0)\n",
        "    mean_of_classes.append(curr_mean)\n",
        "    curr_covariance = np.cov(curr_class ,rowvar= False)\n",
        "    covariance_of_classes.append(curr_covariance)\n",
        "#print(mean_of_classes[i].shape)\n",
        "# computing the prior probabilities\n",
        "dict_count = {}\n",
        "for i in range(10) :\n",
        "    for j in range(len(x_coord_train_vectorized)) :\n",
        "        if y_coord_train[j] == i and i not in dict_count :\n",
        "            dict_count[i] = 1\n",
        "        elif y_coord_train[j] == i and i in dict_count :\n",
        "            dict_count[i] += 1\n",
        "#computing the QDA on the given dataset using the formula\n",
        "inverse_cov = []\n",
        "for i in range(10) :\n",
        "    #print(np.linalg.det(covariance_of_classes[i] + (0.000001)*(np.identity(covariance_of_classes[i].shape[0]))))\n",
        "    inverse_cov.append(np.linalg.inv(covariance_of_classes[i] + (1e-6)*(np.identity(covariance_of_classes[i].shape[0]))))\n",
        "def QDA1(mean , inverse_cov , x , prior):\n",
        "    # print(x.shape, inverse_cov.shape, mean.shape)\n",
        "    return (np.transpose(x) @ (-0.5 * inverse_cov) @ x) + (np.transpose(inverse_cov @ mean ) @ x) + (-0.5 * np.transpose(mean) @ inverse_cov @ mean) + prior\n",
        "#print(\"The accuracies are :\\n\")\n",
        "matching_count = 0\n",
        "class_count_fromQDA = {}\n",
        "class_count_inreal = {}\n",
        "for i in range(len(x_coord_test_vectorized)):\n",
        "    if y_coord_test[i] not in class_count_inreal :\n",
        "        class_count_inreal[y_coord_test[i]] = 1\n",
        "    elif y_coord_test[i] in class_count_inreal :\n",
        "         class_count_inreal[y_coord_test[i]] += 1\n",
        "for i in range(len(x_coord_test_vectorized)):\n",
        "    discriminant_values = []\n",
        "    for j in range(10) :\n",
        "        discriminant_values.append(QDA1(mean_of_classes[j] , inverse_cov[j] , x_coord_test_vectorized[i] , np.log(dict_count[j]/60000)))\n",
        "    #print(discriminant_values)\n",
        "    max_index = np.argmax(discriminant_values)\n",
        "    #print(max_index)\n",
        "    if max_index == y_coord_test[i]:\n",
        "        matching_count +=1\n",
        "        if max_index not in class_count_fromQDA:\n",
        "            class_count_fromQDA[max_index] = 1\n",
        "        elif max_index in class_count_fromQDA :\n",
        "            class_count_fromQDA[max_index] += 1\n",
        "print(\"Accuracy is: \",matching_count / 100,\"%\")\n",
        "\n",
        "for x in class_count_fromQDA :\n",
        "    print(\"Accuracy of class \", x ,\" is: \",(class_count_fromQDA[x]/class_count_inreal[x])*100 ,\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cZx_BKTqNy5m",
        "outputId": "35e992b1-1ce9-4d91-ed78-977a7b88f16a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1000, 784)\n",
            "(784, 1000)\n"
          ]
        }
      ],
      "source": [
        "#Question 2\n",
        "\n",
        "# taking the 100 samples from each class and creating 784 X 1000 data matrix .\n",
        "new_train_set = []\n",
        "\n",
        "for i in range(10):\n",
        "    class_samples = []\n",
        "    counter = 0\n",
        "    for j in range(len(x_coord_train_vectorized)):\n",
        "        if y_coord_train[j] == i:\n",
        "            class_samples.append(x_coord_train_vectorized[j])\n",
        "            counter += 1\n",
        "            if counter == 100:\n",
        "                break\n",
        "    new_train_set.extend(class_samples)\n",
        "X = np.array(new_train_set)\n",
        "print(X.shape)\n",
        "X = X.T\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(784, 1)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X)):\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X[i])):\n\u001b[1;32m---> 24\u001b[0m         MSE \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ((X[i][j] \u001b[38;5;241m-\u001b[39m X_recon[i][j])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe MSE of coming out to be:\u001b[39m\u001b[38;5;124m\"\u001b[39m,MSE)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# removing the mean from X .\n",
        "mean_of_X = np.mean(X,axis=1,keepdims=True)\n",
        "print(mean_of_X.shape)\n",
        "X_centralized = X-mean_of_X\n",
        "#print(X_centralized.shape)\n",
        "# computing covariance S of X\n",
        "S = (X_centralized @ X_centralized.T )/ 999\n",
        "\n",
        "S_eigenvalues , S_eigenvectors = np.linalg.eigh(S)\n",
        "#print(S_eigenvectors)\n",
        "sorted_S  = np.argsort(S_eigenvalues)[::-1]\n",
        "S_eigenvalues = S_eigenvalues[sorted_S]\n",
        "S_eigenvectors = S_eigenvectors[:,sorted_S]\n",
        "#print(S_eigenvalues)\n",
        "U = S_eigenvectors\n",
        "#print(U.shape)\n",
        "Y = U.T @ X_centralized\n",
        "X_recon = U @ Y  + mean_of_X\n",
        "#print(X_recon.shape)\n",
        "MSE = 0\n",
        "\n",
        "for i in range(len(X)):\n",
        "    for j in range(len(X[i])):\n",
        "        MSE += ((X[i][j] - X_recon[i][j])**2)\n",
        "\n",
        "print(\"The MSE of coming out to be:\",MSE)\n",
        "print(\"----------------------------------\")\n",
        "# finding QDA for Xtest for all values of p.\n",
        "p_values = [ 5 ,10 ,20]\n",
        "for p in p_values :\n",
        "    print(\"Image for p=\",p,\"is:\")\n",
        "    Up = U[:,:p]\n",
        "    Y = Up.T @ X_centralized\n",
        "    X_recon = (Up @ Y) + mean_of_X\n",
        "    reconstruction_of_image = X_recon.reshape(28,28,-1)\n",
        "    plt.figure(figsize=(5,10))\n",
        "    for i in range(10):\n",
        "        for j in range(5) :\n",
        "            plt.subplot(10,5,i*5 + j +1)\n",
        "            plt.imshow(reconstruction_of_image[:,:,i*100+j],cmap='gray')\n",
        "            plt.axis('off')\n",
        "    plt.show()\n",
        "    print(\"------------------------------------------------------\")\n",
        "new_train_set = []\n",
        "prior_prob = {}\n",
        "for i in range(10):\n",
        "    class_samples = []\n",
        "    counter = 0\n",
        "    for j in range(len(x_coord_train_vectorized)):\n",
        "        if y_coord_train[j] == i:\n",
        "            class_samples.append(x_coord_train_vectorized[j])\n",
        "            counter += 1\n",
        "            if counter == 6000: # approx taking the whole dataset , as for some categories number of values may exceed 6000 , but we take them as 6000 and break .\n",
        "                break\n",
        "    prior_prob[i] = counter\n",
        "    new_train_set.extend(class_samples)\n",
        "X = np.array(new_train_set)\n",
        "X = X.T\n",
        "print(X.shape)\n",
        "mean_of_X = np.mean(X,axis=1,keepdims=True)\n",
        "X_centralized = X-mean_of_X\n",
        "S = (X_centralized @ X_centralized.T )/ 59999\n",
        "\n",
        "S_eigenvalues , S_eigenvectors = np.linalg.eigh(S)\n",
        "#print(S_eigenvectors)\n",
        "sorted_S  = np.argsort(S_eigenvalues)[::-1]\n",
        "S_eigenvalues = S_eigenvalues[sorted_S]\n",
        "S_eigenvectors = S_eigenvectors[:,sorted_S]\n",
        "#print(S_eigenvalues)\n",
        "U = S_eigenvectors\n",
        "mean_of_X = mean_of_X.T\n",
        "X_centralized = X_centralized.T\n",
        "#print(X.shape , mean_of_X.shape , X_centralized.shape)\n",
        "# for x in prior_prob :\n",
        "#   print(prior_prob[x])\n",
        "for p in p_values :\n",
        "    Up = U[:,:p]\n",
        "  #  print(X_centralized.shape , Up.shape)\n",
        "    Y = np.dot(X_centralized,Up)\n",
        "    new_mean = []\n",
        "    new_cov = []\n",
        "    new_inverse_cov =[]\n",
        "    for i in range(10) :\n",
        "        sample_set = Y[i*6000 : (i+1)*6000]\n",
        "       #print(sample_set)\n",
        "        new_mean.append(np.mean(sample_set  ,axis= 0))\n",
        "        new_cov.append(np.cov(sample_set , rowvar=False))\n",
        "    for i in range(10) :\n",
        "        new_inverse_cov.append(np.linalg.inv(new_cov[i] + (1e-6)*np.identity(new_cov[i].shape[0])))\n",
        "    #print(x_coord_test_vectorized.shape, mean_of_X.T.shape)\n",
        "    Y_test = np.dot(x_coord_test_vectorized - mean_of_X , Up)\n",
        "    matching_count_short = 0\n",
        "    class_short_in_real = {}\n",
        "    class_short_in_QDA = {}\n",
        "    for i in range(len(Y_test)) :\n",
        "        if y_coord_test[i] not in class_short_in_real :\n",
        "            class_short_in_real[y_coord_test[i]] = 1\n",
        "        elif y_coord_test[i] in class_short_in_real:\n",
        "            class_short_in_real[y_coord_test[i]] += 1\n",
        "\n",
        "    for i in range(len(Y_test)) :\n",
        "        discriminant_values_short = []\n",
        "        for j in range(10) :\n",
        "            discriminant_values_short.append(QDA1(new_mean[j] , new_inverse_cov[j] , Y_test[i] ,np.log(prior_prob[j]) ))\n",
        "        max_index_short = np.argmax(discriminant_values_short)\n",
        "        if max_index_short == y_coord_test[i] :\n",
        "            matching_count_short += 1\n",
        "            if max_index_short not in class_short_in_QDA :\n",
        "                class_short_in_QDA[max_index_short] = 1\n",
        "            elif max_index_short in class_short_in_QDA :\n",
        "                class_short_in_QDA[max_index_short]+=1\n",
        "    print(\"Accuracy for p=\",p,\"is:\",matching_count_short / 100,\"%\")\n",
        "\n",
        "    for x in class_short_in_QDA:\n",
        "        print(\"Accuracy of class \",x,\" is \",(class_short_in_QDA[x]/class_short_in_real[x])*100,\"%\")\n",
        "    print(\"------------------------------------------------------------------------------------\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
